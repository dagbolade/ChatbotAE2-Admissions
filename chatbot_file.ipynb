{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27380e148900cdd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Main Chabot File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T04:16:34.359605Z",
     "start_time": "2024-03-02T04:16:26.544763600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\dagbo\\OneDrive\\ChatbotAE2\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "WARNING:tensorflow:From D:\\Users\\dagbo\\OneDrive\\ChatbotAE2\\.venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# Add any other required imports here (e.g., tokenizer, label encoder)\n",
    "\n",
    "# Load the model and other necessary utilities\n",
    "model = load_model('solentBot_model.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5b67e5c439cb51",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T04:16:34.962441500Z",
     "start_time": "2024-03-02T04:16:34.363509Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer and encoder from pickle files\n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "with open('encoder.pickle', 'rb') as enc:\n",
    "    encoder = pickle.load(enc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc91b522988a13",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T04:16:53.893400Z",
     "start_time": "2024-03-02T04:16:34.974153700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solentbot started....... Say 'stop' or type 'close' to exit.\n",
      "Speak Anything, i'm listening... :\n",
      "Sorry could not recognize what you said\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import speech_recognition as sr\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "intents = json.loads(open('intents.json').read())\n",
    "\n",
    "words = pickle.load(open('words.pkl', 'rb'))\n",
    "classes = pickle.load(open('classes.pkl', 'rb'))\n",
    "context = {} #context is used to store the context of the conversation\n",
    "\n",
    "\n",
    "# create a function to handle speech recognition\n",
    "def recognize_speech():\n",
    "    r = sr.Recognizer() # initialize recognizer\n",
    "    with sr.Microphone() as source: # mention source it will be either Microphone or audio files.\n",
    "        print(\"Speak Anything, i'm listening... :\")\n",
    "        audio = r.listen(source)\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            print(\"You said : {}\".format(text))\n",
    "            return text\n",
    "        except:\n",
    "            print(\"Sorry could not recognize what you said\")\n",
    "            return input(\"Enter your message : \")\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    words_sentence = nltk.word_tokenize(sentence)\n",
    "    words_sentence = [lemmatizer.lemmatize(word) for word in words_sentence]\n",
    "    return words_sentence\n",
    "\n",
    "def words_box(sentence, show_details=True):\n",
    "     # tokenize the pattern\n",
    "    words_sentence = clean_sentence(sentence)\n",
    "    box = [0] * len(words)\n",
    "    for j in words_sentence:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == j:\n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                box[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % word)\n",
    "    return np.array(box) \n",
    "\n",
    "def prediction(sentence):\n",
    "    # filter out predictions below a threshold\n",
    "    bd = words_box(sentence,show_details = False)\n",
    "    res = model.predict(np.array([bd]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    \n",
    "    results.sort(key = lambda x: x[1], reverse = True)\n",
    "    get_back_list = []\n",
    "    for r in results:\n",
    "        get_back_list.append({'intent': classes[r[0]], 'probability': str(r[1])})\n",
    "    return get_back_list\n",
    "\n",
    "def get_reply(intents_list, intents_json):\n",
    "    tag = intents_list[0]['intent']\n",
    "    all_intents = intents_json['intents']\n",
    "    for i in all_intents:\n",
    "        if i['tag'] == tag:\n",
    "            return random.choice(i['responses'])\n",
    "            \n",
    "    return \"Sorry, I don't understand. Can you please rephrase?\"\n",
    "\n",
    "# function to speak the text\n",
    "def speak(text):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(\"response.mp3\")\n",
    "    os.system(\"mpg321 response.mp3\")\n",
    "\n",
    "# Chatbot loop with speech recognition\n",
    "print(\"Solentbot started....... Say 'stop' or type 'close' to exit.\")\n",
    "\n",
    "while True:\n",
    "    message = recognize_speech()\n",
    "    if message.lower() in ['stop', 'exit', 'bye', 'quit', 'end']:\n",
    "        speak(\"Goodbye! Feel free to return anytime you have more questions.\")\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    pred = prediction(message)\n",
    "    response = get_reply(pred, intents)\n",
    "    print(response)\n",
    "    speak(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e831e700660b999",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T04:16:53.898283100Z",
     "start_time": "2024-03-02T04:16:53.895346100Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
